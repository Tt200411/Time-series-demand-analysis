{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from ModelBase.Transformer_LSTM import*\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "import tqdm\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss(pred, label):\n",
    "    loss = torch.nn.functional.mse_loss(pred, label, size_average=True)\n",
    "    return loss\n",
    "\n",
    "def train_once(encoder, decoder, dataloader, encoder_optim, decoder_optim, device):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    loader = tqdm.tqdm(dataloader, desc=\"Training\")\n",
    "    loss_epoch = 0\n",
    "    \n",
    "    for data, label in loader:\n",
    "        data = data.float().to(device)  # 转换数据类型为 float 并移动到 GPU\n",
    "        label = label.float().to(device)  # 转换标签类型为 float 并移动到 GPU\n",
    "\n",
    "        encoder_optim.zero_grad()\n",
    "        decoder_optim.zero_grad()\n",
    "        \n",
    "        # 数据传入编码器\n",
    "        encoded_data = encoder(data)\n",
    "        \n",
    "        # 解码器输入初始化，这里使用了全零张量\n",
    "        decoder_input = torch.zeros_like(label).to(device)  # 确保在 GPU 上\n",
    "        \n",
    "        print(encoded_data.shape)\n",
    "        print(decoder_input.shape)\n",
    "        # 数据传入解码器\n",
    "        decoded_output = decoder(encoded_data, decoder_input)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = l2_loss(decoded_output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 更新优化器\n",
    "        encoder_optim.step()\n",
    "        decoder_optim.step()\n",
    "        \n",
    "        # 统计损失值\n",
    "        loss_epoch += loss.item()\n",
    "        \n",
    "        # 更新进度条显示当前批次的损失\n",
    "        loader.set_postfix(loss=loss.item())\n",
    "    \n",
    "    # 返回平均损失\n",
    "    return loss_epoch / len(dataloader)\n",
    "\n",
    "def eval_once(encoder, decoder, dataloader, device):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    loader = tqdm.tqdm(dataloader, desc=\"Evaluating\")\n",
    "    loss_epoch = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for idx, (data, label) in enumerate(loader):\n",
    "        data = data.float().to(device)\n",
    "        label = label.float().to(device)\n",
    "        decoder_input = torch.zeros_like(label).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            encoded_data = encoder(data)\n",
    "            decoded_output = decoder(encoded_data, decoder_input).squeeze(1)\n",
    "        \n",
    "        loss = l2_loss(decoded_output, label)\n",
    "        loss_epoch += loss.item()\n",
    "        preds += decoded_output.tolist()\n",
    "        labels += label.tolist()\n",
    "        loader.set_postfix(loss=loss.item())\n",
    "    loss_epoch /= len(loader)\n",
    "    return loss_epoch\n",
    "\n",
    "def eval_plot(encoder, decoder, dataloader, train_losses, val_losses, device):\n",
    "    dataloader.shuffle = False\n",
    "    preds = []\n",
    "    labels = []\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    loader = tqdm.tqdm(dataloader, desc=\"Plotting\")\n",
    "    for idx, (data, label) in enumerate(loader):\n",
    "        data = data.float().to(device)\n",
    "        label = label.float().to(device)\n",
    "        decoder_input = torch.zeros_like(label).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            encoded_data = encoder(data)\n",
    "            decoded_output = decoder(encoded_data, decoder_input)\n",
    "        \n",
    "        preds += decoded_output.tolist()\n",
    "        labels += label.tolist()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    data_x = list(range(len(preds)))\n",
    "    ax.plot(data_x, preds, label='predict', color='red')\n",
    "    ax.plot(data_x, labels, label='ground truth', color='blue')\n",
    "    ax.plot(train_losses, label='train loss', color='green')  # 添加训练损失曲线\n",
    "    ax.plot(val_losses, label='val loss', color='orange')  # 添加评估损失曲线\n",
    "    plt.savefig('shangzheng-tran-lstm.png')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    input_data = np.load(\"Preprocessing/sample.npy\")\n",
    "    target_data = np.load(\"Preprocessing/target.npy\")\n",
    "\n",
    "    input_data = torch.tensor(input_data, dtype=torch.float32)\n",
    "    target_data = torch.tensor(target_data, dtype=torch.float32)\n",
    "\n",
    "    # Split data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(input_data, target_data, test_size=0.2, random_state=42)\n",
    "    # Create DataLoader\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize model and optimizers\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Running on device: {device}\")\n",
    "    encoder = TransAm().to(device)\n",
    "    decoder = AttnDecoder(code_hidden_size=88, hidden_size=64, time_step=24).to(device)  # Adjust time_step according to your data\n",
    "    encoder_optim = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "    decoder_optim = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "    total_epoch = 201\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch_idx in range(total_epoch):\n",
    "        train_loss = train_once(encoder, decoder, train_loader, encoder_optim, decoder_optim, device)\n",
    "        train_losses.append(train_loss)\n",
    "        print(f\"Epoch: {epoch_idx}, Train Loss: {train_loss}\")\n",
    "\n",
    "        if epoch_idx % 5 == 0:\n",
    "            val_loss = eval_once(encoder, decoder, val_loader, device)\n",
    "            val_losses.append(val_loss)\n",
    "            print(f\"Epoch: {epoch_idx}, Validation Loss: {val_loss}\")\n",
    "            eval_plot(encoder, decoder, val_loader, train_losses, val_losses, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                 | 0/73 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data shape: torch.Size([32, 44])\n",
      "Decoder input shape: torch.Size([32, 44])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_30640\\570736540.py:122: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 44])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = torch.nn.functional.mse_loss(pred, label, reduction='mean')  # size_average=True 已弃用，改用 reduction='mean'\n",
      "Training:   0%|                                                                                 | 0/73 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (44) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 260\u001b[0m\n\u001b[0;32m    257\u001b[0m             eval_plot(encoder, decoder, val_loader, train_losses, val_losses, device)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 260\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 249\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    246\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_epoch):\n\u001b[1;32m--> 249\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 151\u001b[0m, in \u001b[0;36mtrain_once\u001b[1;34m(encoder, decoder, dataloader, encoder_optim, decoder_optim, device)\u001b[0m\n\u001b[0;32m    148\u001b[0m decoded_output \u001b[38;5;241m=\u001b[39m decoder(encoded_data\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m), decoder_input)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# 计算损失\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43ml2_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# 更新优化器\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 122\u001b[0m, in \u001b[0;36ml2_loss\u001b[1;34m(pred, label)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21ml2_loss\u001b[39m(pred, label):\n\u001b[1;32m--> 122\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# size_average=True 已弃用，改用 reduction='mean'\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\torchDeepL\\lib\\site-packages\\torch\\nn\\functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3292\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\torchDeepL\\lib\\site-packages\\torch\\functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (44) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "import tqdm\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim \n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=44):  # max_len设置为44，因为有44个特征\n",
    "        super(PositionalEncoding, self).__init__()       \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)  # 变为 (max_len, 1, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, 44, d_model]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self, feature_size=64, num_layers=6, dropout=0.1):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size, max_len=44)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=8, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.decoder = nn.Linear(feature_size, 1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [batch_size, 44]\n",
    "        \"\"\"\n",
    "        src = src.unsqueeze(-1)  # 变为 [batch_size, 44, 1]\n",
    "        src = self.pos_encoder(src)\n",
    "        src = src.permute(1, 0, 2)  # 变为 [44, batch_size, 1]\n",
    "        if self.src_mask is None or self.src_mask.size(0) != src.size(0):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(src.size(0)).to(device)\n",
    "            self.src_mask = mask\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        output = output.permute(1, 0, 2).squeeze(-1)  # 变为 [batch_size, 44]\n",
    "        return output\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, code_hidden_size, hidden_size, time_step):\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        self.code_hidden_size = code_hidden_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.T = time_step\n",
    "\n",
    "        self.attn1 = nn.Linear(in_features=hidden_size + 44, out_features=code_hidden_size)\n",
    "        self.attn2 = nn.Linear(in_features=code_hidden_size, out_features=code_hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.attn3 = nn.Linear(in_features=code_hidden_size, out_features=1)\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=self.hidden_size, num_layers=1)\n",
    "        self.tilde = nn.Linear(in_features=self.code_hidden_size + 1, out_features=1)\n",
    "        self.fc1 = nn.Linear(in_features=hidden_size + 44, out_features=hidden_size)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "    def forward(self, h, y_seq):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h: Tensor, shape [batch_size, 44]\n",
    "            y_seq: Tensor, shape [batch_size, 1]\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        batch_size = h.size(0)\n",
    "        seq_len = h.size(1)\n",
    "        feature_size = h.size(2)\n",
    "        d = self.init_variable(1, batch_size, self.hidden_size).to(device)\n",
    "        s = self.init_variable(1, batch_size, self.hidden_size).to(device)\n",
    "        h = h.unsqueeze(-1)  # 变为 [batch_size, 44, 1]\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(self.T):\n",
    "            h_t = h[:, t, :].unsqueeze(0)  # 从 h 中取出第 t 个时间步，变为 [1, batch_size, feature_size]\n",
    "            x = torch.cat((d, h_t), dim=2)  # 拼接 d 和 h_t，变为 [1, batch_size, hidden_size + feature_size]\n",
    "            h1 = self.attn1(x)\n",
    "            h1 = h1.squeeze(0)  # 去掉第一维度，变为 [batch_size, code_hidden_size]\n",
    "            y_t = y_seq[:, t].unsqueeze(1).unsqueeze(0)  # 从 y_seq 中取出第 t 个时间步，变为 [1, batch_size, 1]\n",
    "            _, states = self.lstm(y_t, (d, s))  # 使用d和s作为LSTM的初始状态\n",
    "            d = states[0]\n",
    "            s = states[1]\n",
    "            y_res = self.fc2(self.fc1(torch.cat((d.squeeze(0), h_t.squeeze(0)), dim=1)))  # 确保维度匹配\n",
    "            outputs.append(y_res)\n",
    "\n",
    "        outputs = torch.stack(outputs, dim=1).squeeze(2)  # 变为 [batch_size, 1]\n",
    "        return outputs\n",
    "\n",
    "    def init_variable(self, *args):\n",
    "        zero_tensor = torch.zeros(*args)\n",
    "        return Variable(zero_tensor)\n",
    "\n",
    "# 训练部分代码\n",
    "def l2_loss(pred, label):\n",
    "    loss = torch.nn.functional.mse_loss(pred, label, size_average=True)\n",
    "    return loss\n",
    "\n",
    "def train_once(encoder, decoder, dataloader, encoder_optim, decoder_optim, device):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    loader = tqdm.tqdm(dataloader, desc=\"Training\")\n",
    "    loss_epoch = 0\n",
    "    \n",
    "    for data, label in loader:\n",
    "        data = data.float().to(device)  # 转换数据类型为 float 并移动到 GPU\n",
    "        label = label.float().to(device)  # 转换标签类型为 float 并移动到 GPU\n",
    "\n",
    "        encoder_optim.zero_grad()\n",
    "        decoder_optim.zero_grad()\n",
    "        \n",
    "        # 数据传入编码器\n",
    "        encoded_data = encoder(data)\n",
    "        \n",
    "        # 解码器输入初始化，这里使用了全零张量\n",
    "        decoder_input = torch.zeros_like(label).to(device)  # 确保在 GPU 上\n",
    "        \n",
    "        print(encoded_data.shape)\n",
    "        print(decoder_input.shape)\n",
    "        # 数据传入解码器\n",
    "        decoded_output = decoder(encoded_data, decoder_input)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = l2_loss(decoded_output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 更新优化器\n",
    "        encoder_optim.step()\n",
    "        decoder_optim.step()\n",
    "        \n",
    "        # 统计损失值\n",
    "        loss_epoch += loss.item()\n",
    "        \n",
    "        # 更新进度条显示当前批次的损失\n",
    "        loader.set_postfix(loss=loss.item())\n",
    "    \n",
    "    # 返回平均损失\n",
    "    return loss_epoch / len(dataloader)\n",
    "\n",
    "def eval_once(encoder, decoder, dataloader, device):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    loader = tqdm.tqdm(dataloader, desc=\"Evaluating\")\n",
    "    loss_epoch = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for idx, (data, label) in enumerate(loader):\n",
    "        data = data.float().to(device)\n",
    "        label = label.float().to(device)\n",
    "        decoder_input = torch.zeros_like(label).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            encoded_data = encoder(data)\n",
    "            decoded_output = decoder(encoded_data, decoder_input).squeeze(1)\n",
    "        \n",
    "        loss = l2_loss(decoded_output, label)\n",
    "        loss_epoch += loss.item()\n",
    "        preds += decoded_output.tolist()\n",
    "        labels += label.tolist()\n",
    "        loader.set_postfix(loss=loss.item())\n",
    "    loss_epoch /= len(loader)\n",
    "    return loss_epoch\n",
    "\n",
    "def eval_plot(encoder, decoder, dataloader, train_losses, val_losses, device):\n",
    "    dataloader.shuffle = False\n",
    "    preds = []\n",
    "    labels = []\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    loader = tqdm.tqdm(dataloader, desc=\"Plotting\")\n",
    "    for idx, (data, label) in enumerate(loader):\n",
    "        data = data.float().to(device)\n",
    "        label = label.float().to(device)\n",
    "        decoder_input = torch.zeros_like(label).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            encoded_data = encoder(data)\n",
    "            decoded_output = decoder(encoded_data, decoder_input)\n",
    "        \n",
    "        preds += decoded_output.tolist()\n",
    "        labels += label.tolist()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    data_x = list(range(len(preds)))\n",
    "    ax.plot(data_x, preds, label='predict', color='red')\n",
    "    ax.plot(data_x, labels, label='ground truth', color='blue')\n",
    "    ax.plot(train_losses, label='train loss', color='green')  # 添加训练损失曲线\n",
    "    ax.plot(val_losses, label='val loss', color='orange')  # 添加评估损失曲线\n",
    "    plt.savefig('shangzheng-tran-lstm.png')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # 加载数据\n",
    "    input_data = np.load(\"Preprocessing/sample.npy\")\n",
    "    target_data = np.load(\"Preprocessing/target.npy\")\n",
    "\n",
    "    input_data = torch.tensor(input_data, dtype=torch.float32)\n",
    "    target_data = torch.tensor(target_data, dtype=torch.float32)\n",
    "\n",
    "    # 将数据划分为训练集和验证集\n",
    "    X_train, X_val, y_train, y_val = train_test_split(input_data, target_data, test_size=0.2, random_state=42)\n",
    "    # 创建DataLoader\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # 初始化模型和优化器\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Running on device: {device}\")\n",
    "    encoder = TransAm().to(device)\n",
    "    decoder = AttnDecoder(code_hidden_size=88, hidden_size=64, time_step=44).to(device)  # Adjust time_step according to your data\n",
    "    encoder_optim = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "    decoder_optim = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "    total_epoch = 201\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch_idx in range(total_epoch):\n",
    "        train_loss = train_once(encoder, decoder, train_loader, encoder_optim, decoder_optim, device)\n",
    "        train_losses.append(train_loss)\n",
    "        print(f\"Epoch: {epoch_idx}, Train Loss: {train_loss}\")\n",
    "\n",
    "        if epoch_idx % 5 == 0:\n",
    "            val_loss = eval_once(encoder, decoder, val_loader, device)\n",
    "            val_losses.append(val_loss)\n",
    "            print(f\"Epoch: {epoch_idx}, Validation Loss: {val_loss}\")\n",
    "            eval_plot(encoder, decoder, val_loader, train_losses, val_losses, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
