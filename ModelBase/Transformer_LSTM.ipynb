{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "import tqdm\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim \n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=24):  # max_len设置为24，因为有24个时间步\n",
    "        super(PositionalEncoding, self).__init__()       \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)  # 变为 (max_len, 1, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, 118, 24, d_model]\n",
    "        \"\"\"\n",
    "        x = x.permute(2, 0, 1, 3)  # 变为 (24, batch_size, 118, d_model)\n",
    "        x = x + self.pe[:x.size(0), :, :].unsqueeze(2)  # 加位置编码\n",
    "        x = x.permute(1, 2, 0, 3)  # 变回 (batch_size, 118, 24, d_model)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self, feature_size=64, num_layers=6, dropout=0.1):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=8, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=feature_size, nhead=8, dropout=dropout)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.decoder = nn.Linear(feature_size, 1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [batch_size, 118, 24]\n",
    "        \"\"\"\n",
    "        print(src.shape)\n",
    "        src = src.unsqueeze(-1)  # 变为 [batch_size, 118, 24, 1]\n",
    "        print(src.shape)\n",
    "        src = self.pos_encoder(src)\n",
    "        \n",
    "        \n",
    "        batch_size, num_nodes, seq_len, d_model = src.shape\n",
    "        src = src.view(seq_len, batch_size * num_nodes, d_model)  # 变为 [24, batch_size * 118, d_model]\n",
    "\n",
    "        if self.src_mask is None or self.src_mask.size(0) != seq_len:\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(seq_len).to(device)\n",
    "            self.src_mask = mask\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        output = output.view(seq_len, batch_size, num_nodes, d_model)  # 变回 [24, batch_size, 118, d_model]\n",
    "        output = output.permute(1, 2, 0, 3)  # 变为 [batch_size, 118, 24, d_model]\n",
    "        output = self.decoder(output)  # [batch_size, 118, 24, 1]\n",
    "        output = output.squeeze(-1)  # [batch_size, 118, 24]\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "    \n",
    "      \n",
    "    \n",
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, code_hidden_size, hidden_size, time_step):\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        self.code_hidden_size = code_hidden_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.T = time_step\n",
    "\n",
    "        self.attn1 = nn.Linear(in_features=hidden_size + 118, out_features=code_hidden_size)\n",
    "        self.attn2 = nn.Linear(in_features=code_hidden_size, out_features=code_hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.attn3 = nn.Linear(in_features=code_hidden_size, out_features=1)\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=self.hidden_size, num_layers=1)\n",
    "        self.tilde = nn.Linear(in_features=self.code_hidden_size + 1, out_features=1)\n",
    "        self.fc1 = nn.Linear(in_features=hidden_size + 118, out_features=hidden_size)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "    def forward(self, h, y_seq):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h: Tensor, shape [batch_size, 118, 24]\n",
    "            y_seq: Tensor, shape [batch_size, 24]\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        batch_size = h.size(0)\n",
    "        seq_len = h.size(1)\n",
    "        feature_size = h.size(2)\n",
    "        d = self.init_variable(1, batch_size, self.hidden_size).to(device)\n",
    "        s = self.init_variable(1, batch_size, self.hidden_size).to(device)\n",
    "        h = h.transpose(1, 2)  # 变为 [batch_size, 24, 118]\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(self.T):\n",
    "            h_t = h[:, t, :].unsqueeze(0)  # 从 h 中取出第 t 个时间步，变为 [1, batch_size, feature_size]\n",
    "            x = torch.cat((d, h_t), dim=2)  # 拼接 d 和 h_t，变为 [1, batch_size, hidden_size + feature_size]\n",
    "            h1 = self.attn1(x)\n",
    "            h1 = h1.squeeze(0)  # 去掉第一维度，变为 [batch_size, code_hidden_size]\n",
    "            y_t = y_seq[:, t].unsqueeze(1).unsqueeze(0)  # 从 y_seq 中取出第 t 个时间步，变为 [1, batch_size, 1]\n",
    "            _, states = self.lstm(y_t, (d, s))  # 使用d和s作为LSTM的初始状态\n",
    "            d = states[0]\n",
    "            s = states[1]\n",
    "            y_res = self.fc2(self.fc1(torch.cat((d.squeeze(0), h_t.squeeze(0)), dim=1)))  # 确保维度匹配\n",
    "            outputs.append(y_res)\n",
    "\n",
    "        outputs = torch.stack(outputs, dim=1).squeeze(2)  # 变为 [batch_size, 24]\n",
    "        return outputs\n",
    "\n",
    "    def init_variable(self, *args):\n",
    "        zero_tensor = torch.zeros(*args)\n",
    "        return Variable(zero_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
